# -*- coding: utf-8 -*-
"""GradioGUI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iZM661NPzMyP8oZKE7fkfUjcMWG9SVY5
"""

!pip install gradio

import torch
from torchvision import transforms
from PIL import Image
import gradio as gr

# Define the transformation for the input image
transform = transforms.Compose([
    transforms.Resize((224, 224)),  # Resizing the image for EfficientNet input size
    transforms.ToTensor(),  # Convert image to tensor
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalize using pre-trained model's mean and std
])

# Class labels dictionary
class_labels = {
    0: 'heh_middle', 1: 'noon_end', 2: 'ain_begin', 3: 'ain_end', 4: 'ain_middle', 5: 'ain_regular',
    6: 'alif_end', 7: 'alif_hamza', 8: 'alif_regular', 9: 'beh_begin', 10: 'beh_end', 11: 'beh_middle',
    12: 'beh_regular', 13: 'dal_end', 14: 'dal_regular', 15: 'feh_begin', 16: 'feh_end', 17: 'feh_middle',
    18: 'feh_regular', 19: 'heh_begin', 20: 'heh_end', 21: 'heh_regular', 22: 'jeem_begin', 23: 'jeem_end',
    24: 'jeem_middle', 25: 'jeem_regular', 26: 'kaf_begin', 27: 'kaf_end', 28: 'kaf_middle', 29: 'kaf_regular',
    30: 'lam_alif', 31: 'lam_begin', 32: 'lam_end', 33: 'lam_middle', 34: 'lam_regular', 35: 'meem_begin',
    36: 'meem_end', 37: 'meem_middle', 38: 'meem_regular', 39: 'noon_begin', 40: 'noon_middle',
    41: 'noon_regular', 42: 'qaf_begin', 43: 'qaf_end', 44: 'qaf_middle', 45: 'qaf_regular', 46: 'raa_end',
    47: 'raa_regular', 48: 'sad_begin', 49: 'sad_end', 50: 'sad_middle', 51: 'sad_regular', 52: 'seen_begin',
    53: 'seen_end', 54: 'seen_middle', 55: 'seen_regular', 56: 'tah_end', 57: 'tah_middle', 58: 'tah_regular',
    59: 'waw_end', 60: 'waw_regular', 61: 'yaa_begin', 62: 'yaa_end', 63: 'yaa_middle', 64: 'yaa_regular',
}

# Function to make predictions
def predict(image):
    # Convert the uploaded image to RGB and apply transformations
    input_image = Image.fromarray(image).convert('RGB')
    input_tensor = transform(input_image).unsqueeze(0)  # Add batch dimension
    input_tensor = input_tensor.to(device)

    with torch.no_grad():
        # Get predictions from the model
        output = model(input_tensor)

    # Get the predicted class (as a number)
    _, predicted_class = torch.max(output, 1)
    predicted_class = predicted_class.item()

    # Map the predicted class number to its corresponding label using class_labels
    predicted_label = class_labels[predicted_class]

    return predicted_label  # Return the predicted label

# Load your EfficientNet model (replace with the actual model loading code)
# Added map_location argument to load the model on CPU even if it was saved on GPU
model = torch.load('/content/efficientnet_b7_complete_model.pth', map_location=torch.device('cpu'))
model.eval()  # Set the model to evaluation mode

# Set the device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

# Create a Gradio interface
iface = gr.Interface(
    fn=predict,  # The function that takes the image as input and returns the predicted class
    inputs=gr.Image(type="numpy", label="Upload Image"),  # Image input in numpy format
    outputs=gr.Label(num_top_classes=1, label="Predicted Class"),  # Display the predicted label
    title="Arabic Letters Classification",  # Title for the interface
    description="Upload an image of Arabic letters to classify them."
)

# Launch the Gradio interface
iface.launch()