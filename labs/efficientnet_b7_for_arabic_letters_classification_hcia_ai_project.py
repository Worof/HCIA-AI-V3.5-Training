# -*- coding: utf-8 -*-
"""Efficientnet_B7_For_Arabic_Letters_Classification_HCIA-AI_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rTUTMA9olsd_-FkRgowJTeGRX45UK47f
"""

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES
# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.

import os
import sys
from tempfile import NamedTemporaryFile
from urllib.request import urlopen
from urllib.parse import unquote, urlparse
from urllib.error import HTTPError
from zipfile import ZipFile
import tarfile
import shutil

CHUNK_SIZE = 40960
DATA_SOURCE_MAPPING = 'arabic-letters-classification:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F65471%2F7211464%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240919%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240919T094402Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Da855e91af449d2e243c48ae580eb457a42b0fdf1b4bd42b84759693288e66ee33fec5310faff353039b887a30c8336e541d527b2a978138b59e84ee9b4e18d314521957b44a3b8a9defbe50dd36dc9c08337363646fcf89c4919bfd722aa430e75f1891aa073da85354abd32a02d80df2238468885ec5463faf49114c54aec081d2ac5844ef5c3b318f415f5bcd0caf57db5c37ddc87478efc669c98d72b7f2f6377d33bc53c8cf9075460f93688af58e7c877803156ca682f81873ba8621c9273a23ceb66a750992e00a13b03555e22dfeaeeb271d445add4c9b926fa686724bfc8e48c5a8e1904e32b3c5e7082208ef90d2e82478807e3e89d8e101160e05a'

KAGGLE_INPUT_PATH='/kaggle/input'
KAGGLE_WORKING_PATH='/kaggle/working'
KAGGLE_SYMLINK='kaggle'

!umount /kaggle/input/ 2> /dev/null
shutil.rmtree('/kaggle/input', ignore_errors=True)
os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)
os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)

try:
  os.symlink(KAGGLE_INPUT_PATH, os.path.join("..", 'input'), target_is_directory=True)
except FileExistsError:
  pass
try:
  os.symlink(KAGGLE_WORKING_PATH, os.path.join("..", 'working'), target_is_directory=True)
except FileExistsError:
  pass

for data_source_mapping in DATA_SOURCE_MAPPING.split(','):
    directory, download_url_encoded = data_source_mapping.split(':')
    download_url = unquote(download_url_encoded)
    filename = urlparse(download_url).path
    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)
    try:
        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:
            total_length = fileres.headers['content-length']
            print(f'Downloading {directory}, {total_length} bytes compressed')
            dl = 0
            data = fileres.read(CHUNK_SIZE)
            while len(data) > 0:
                dl += len(data)
                tfile.write(data)
                done = int(50 * dl / int(total_length))
                sys.stdout.write(f"\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded")
                sys.stdout.flush()
                data = fileres.read(CHUNK_SIZE)
            if filename.endswith('.zip'):
              with ZipFile(tfile) as zfile:
                zfile.extractall(destination_path)
            else:
              with tarfile.open(tfile.name) as tarfile:
                tarfile.extractall(destination_path)
            print(f'\nDownloaded and uncompressed: {directory}')
    except HTTPError as e:
        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')
        continue
    except OSError as e:
        print(f'Failed to load {download_url} to path {destination_path}')
        continue

print('Data source import complete.')

import os
import matplotlib.pyplot as plt
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim import lr_scheduler
from torch.utils.data import DataLoader, random_split , Dataset
from torchvision import models, transforms, datasets
from PIL import Image
from sklearn.metrics import confusion_matrix
import csv

"""***CONSTANTS***"""

train_dir = '/kaggle/input/arabic-letters-classification/Final_Arabic_Alpha_dataset/Final_Arabic_Alpha_dataset/train'
num_classes = 65
image_shape = (224, 224)

"""***PREPROCESSING***"""

class MakeDataset(Dataset):
    def __init__(self, root_folder, transform=None):
        self.root_folder = root_folder
        self.transform = transform
        self.classes = sorted(os.listdir(root_folder), key=lambda x: int(x))
        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}
        self.images = self.make_dataset()

    def make_dataset(self):
        images = []
        for label in self.classes:
            label_folder = os.path.join(self.root_folder, label)
            for image_name in os.listdir(label_folder):
                image_path = os.path.join(label_folder, image_name)
                item = (image_path, self.class_to_idx[label])
                images.append(item)
        return images

    def __len__(self):
        return len(self.images)

    def __getitem__(self, index):
        image_path, label = self.images[index]
        image = Image.open(image_path).convert("RGB")

        if self.transform:
            image = self.transform(image)

        return image, label

transform = transforms.Compose([
    transforms.Grayscale(num_output_channels=3),
    transforms.Resize(image_shape),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

dataset = MakeDataset(train_dir, transform=transform)

train_size = int(0.8 * len(dataset))
val_size = int(0.1 * len(dataset))
test_size = len(dataset) - train_size - val_size
train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])

batch_size = 8

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

"""***VISUALIZATION***"""

def show_images(images, labels, ncols=8):
    figure, axes = plt.subplots(nrows=1, ncols=ncols, figsize=(15, 2))
    for i, ax in enumerate(axes):
        ax.imshow(np.transpose(images[i], (1, 2, 0)))
        ax.set_title(f'Class: {labels[i]}')
        ax.axis('off')

data_iter = iter(train_loader)
images, labels = data_iter.__next__()

show_images(images, labels)
plt.show()

"""***MODEL***"""

model = models.efficientnet_b7(pretrained=True)
model.classifier = nn.Sequential(
    nn.Dropout(p=0.2, inplace=True),
    nn.Linear(in_features=2560, out_features=num_classes, bias=True)
)
model.save = 'efficientnet_b7'
model.save_dir = '/kaggle/working'

# Assuming the classifier attribute is 'classifier', get the last layer in the Sequential
last_layer = list(model.classifier.children())[-1]


# Replace it with the correct attribute name
if isinstance(last_layer, nn.Linear):
    in_features = last_layer.in_features
    model.classifier[-1] = nn.Linear(in_features, num_classes)
else:
    raise ValueError("The last layer of the classifier is not Linear, please adjust the code accordingly.")

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.0001)
scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(device)

torch.cuda.empty_cache()

model = model.to(device)

num_epochs = 2
desired_training_accuracy = 99.999
early_stopping_threshold = 5
early_stopping_counter = 0
best_val_loss = float('inf')

# Lists to store training and validation metrics for plotting curves
train_losses = []
train_accuracies = []
val_losses = []
val_accuracies = []
predictions = []
targets = []

for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    correct_train = 0
    total_train = 0

    for i, (inputs, labels) in enumerate(train_loader):
        inputs, labels = inputs.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()

        _, predicted_train = torch.max(outputs.data, 1)
        total_train += labels.size(0)
        correct_train += (predicted_train == labels).sum().item()

        # Print training loss and accuracy every 100 batches
        if i % 100 == 99:
            print(f'Epoch {epoch + 1}/{num_epochs}, Batch {i + 1}/{len(train_loader)}, '
                  f'Training Loss: {running_loss / 100}, Training Accuracy: {100 * correct_train / total_train}')
            running_loss = 0.0

    # Calculate training accuracy after the epoch
    training_accuracy = correct_train / total_train

    # Validation
    model.eval()
    correct_val = 0
    total_val = 0
    val_running_loss = 0.0

    with torch.no_grad():
        for inputs, labels in val_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            val_running_loss += loss.item()

            _, predicted_val = torch.max(outputs.data, 1)
            total_val += labels.size(0)
            correct_val += (predicted_val == labels).sum().item()

            # Append predictions and targets for confusion matrix
            predictions.append(predicted_val.cpu().numpy())
            targets.append(labels.cpu().numpy())

    # Calculate validation accuracy after the epoch
    validation_accuracy = correct_val / total_val
    average_val_loss = val_running_loss / len(val_loader)

    print(f'Epoch {epoch + 1}/{num_epochs}, '
          f'Training Loss: {running_loss / len(train_loader)}, '
          f'Training Accuracy: {100 * training_accuracy}%, '
          f'Validation Loss: {average_val_loss}, '
          f'Validation Accuracy: {100 * validation_accuracy}%')

    # Append training and validation metrics for plotting
    train_losses.append(running_loss / len(train_loader))
    train_accuracies.append(training_accuracy)
    val_losses.append(average_val_loss)
    val_accuracies.append(validation_accuracy)

    scheduler.step()

model.eval()
correct = 0
total = 0

with torch.no_grad():
    for inputs, labels in test_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = model(inputs)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

test_accuracy = correct / total
print(f'Test Accuracy: {100 * test_accuracy}%')

"""***VISUALIZE THE MODEL***"""

# Plotting loss and accuracy curves
plt.figure(figsize=(12, 4))

# Plotting training and validation loss
plt.subplot(1, 2, 1)
plt.plot(train_losses, label='Training Loss')
plt.plot(val_losses, label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training and Validation Loss')
plt.legend()

# Plotting training and validation accuracy
plt.subplot(1, 2, 2)
plt.plot(train_accuracies, label='Training Accuracy')
plt.plot(val_accuracies, label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy (%)')
plt.title('Training and Validation Accuracy')
plt.legend()

plt.tight_layout()
plt.show()

# Confusion Matrix
conf_matrix = confusion_matrix(np.concatenate(predictions), np.concatenate(targets))
print('Confusion Matrix:')

# Print all numbers in the confusion matrix
print('Confusion Matrix:')
for row in conf_matrix:
    for value in row:
        print(value, end=' ')
    print()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix


# Plot the heatmap
plt.figure(figsize=(10, 8))
plt.imshow(conf_matrix, cmap='viridis', interpolation='nearest')
plt.colorbar()
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

"""***PREDICTIONS***"""

model = model
model = model.cuda()

test_directory =  '/kaggle/input/arabic-letters-classification/Final_Arabic_Alpha_dataset/Final_Arabic_Alpha_dataset/test/'
csv_file_path = 'predictions.csv'

transform = transforms.Compose([
    transforms.Resize(image_shape),
    transforms.Grayscale(num_output_channels=3),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

with open(csv_file_path, 'w', newline='') as csvfile:
    csv_writer = csv.writer(csvfile)

    csv_writer.writerow(['ID', 'Label'])

    for filename in sorted(os.listdir(test_directory), key=lambda x: int(x.split('.')[0])):
        if filename.endswith(".jpg") or filename.endswith(".png"):
            image_path = os.path.join(test_directory, filename)

            input_image = Image.open(image_path).convert('RGB')
            input_tensor = transform(input_image).unsqueeze(0)
            input_tensor = input_tensor.cuda()

            with torch.no_grad():
                output = model(input_tensor)

            _, predicted_class = torch.max(output, 1)

            csv_writer.writerow([int(filename.split('.')[0]), predicted_class.item()])

print(f"Predictions saved to: {csv_file_path}")

!pip install gradio

import gradio as gr
import torch
from PIL import Image
import os
from torchvision import transforms

# Load your model
model = model.cuda()  # Ensure your model is on the GPU

# Define image transformation
image_shape = (224, 224)  # Define the appropriate image size for your model
transform = transforms.Compose([
    transforms.Resize(image_shape),
    transforms.Grayscale(num_output_channels=3),  # Assuming the model expects 3 channels
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# Create a dictionary to map predicted numbers to labels
class_labels = {
    0: 'heh_middle',
    1: 'noon_end',
    2:'ain_begin',
    3:'ain_end',
    4:'ain_middle',
    5:'ain_regular',
    6:'alif_end',
    7:'alif_hamza',
    8:'alif_regular',
    9:'beh_begin',
    10: 'beh_end',
    11:'beh_middle',
    12:'beh_regular',
    13:'dal_end',
    14:'dal_regular',
    15:'feh_begin',
    16:'feh_end',
    17:'feh_middle',
    18:'feh_regular',
    19:'heh_begin',
    20:'heh_end',
    21:'heh_regular',
    22:'jeem_begin',
    23:'jeem_end',
    24:'jeem_middle',
    25:'jeem_regular',
    26:'kaf_begin',
    27:'kaf_end',
    28:'kaf_middle',
    29:'kaf_regular',
    30:'lam_alif',
    31:'lam_begin',
    32:'lam_end',
    33:'lam_middle',
    34:'lam_regular',
    35:'meem_begin',
    36:'meem_end',
    37:'meem_middle',
    38:'meem_regular',
    39:'noon_begin',
    40:'noon_middle',
    41:'noon_regular',
    42:'qaf_begin',
    43:'qaf_end',
    44:'qaf_middle',
    45:'qaf_regular',
    46:'raa_end',
    47:'raa_regular',
    48:'sad_begin',
    49:'sad_end',
    50:'sad_middle',
    51:'sad_regular',
    52:'seen_begin',
    53:'seen_end',
    54:'seen_middle',
    55:'seen_regular',
    56:'tah_end',
    57:'tah_middle',
    58:'tah_regular',
    59:'waw_end',
    60:'waw_regular',
    61:'yaa_begin',
    62:'yaa_end',
    63:'yaa_middle',
    64:'yaa_regular',
}

# Function to make predictions
def predict(image):
    input_image = Image.fromarray(image).convert('RGB')  # Convert the uploaded image to RGB
    input_tensor = transform(input_image).unsqueeze(0).cuda()  # Apply transforms and move to GPU

    with torch.no_grad():
        output = model(input_tensor)  # Get predictions from the model

    _, predicted_class = torch.max(output, 1)  # Get the predicted class (as a number)
    predicted_class = predicted_class.item()

    # Map the predicted class number to its corresponding label
    predicted_label = class_labels.get(predicted_class, "Unknown Class")  # Handle unmapped classes

    return predicted_label  # Return the predicted label instead of the number

# Create a Gradio interface
iface = gr.Interface(
    fn=predict,  # The function that takes the image as input and returns the predicted class
    inputs=gr.Image(type="numpy", label="Upload Image"),  # Image input
    outputs=gr.Label(num_top_classes=1, label="Predicted Class"),  # Display the predicted label
    title="Arabic Letters Classification",  # Title for the interface
    description="Upload an image of Arabic letters to classify them."
)

# Launch the interface
iface.launch()